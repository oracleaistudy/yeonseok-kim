{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38620556",
   "metadata": {},
   "source": [
    "### 1. ë””ì½”ë” ê¸°ë°˜ì˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸  \n",
    ": `ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸`ê³¼ `í´ë¡œì¦ˆë“œ ì†ŒìŠ¤ ëª¨ë¸`ë¡œ ë‚˜ë‰¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18370564",
   "metadata": {},
   "source": [
    "### 2. LLM ë¦¬ë”ë³´ë“œ  \n",
    "- `IFEval`: ì•½ 500ê°œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì„ íƒí•˜ì—¬ ì–¸ì–´ ëª¨ë¸ì´ í”„ë¡¬í”„íŠ¸ì˜ ì§€ì‹œë¥¼ ì–¼ë§ˆë‚˜ ì˜ ë”°ë¥´ëŠ”ì§€ í‰ê°€í•œ ê°’  \n",
    "- `BBH`: `ë¹…ë²¤ì¹˜` í‰ê°€ì˜ í•˜ìœ„ ì§‘í•©ìœ¼ë¡œ ë‹¤ë‹¨ê³„ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ì–´ë ¤ìš´ ê³¼ì œë¡œ êµ¬ì„±  \n",
    "- `MATH`: ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´ ìˆ˜í•™ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ë²¤ì¹˜ë§ˆí¬  \n",
    "- `GPQA`: í™”í•™, ìƒë¬¼í•™, ë¬¼ë¦¬í•™ ë¶„ì•¼ì—ì„œ ë°•ì‚¬ ìˆ˜ì¤€ì˜ 448ê°œì˜ ê°ê´€ì‹ ë¬¸ì œë¥¼ í‘¸ëŠ” ë²¤ì¹˜ë§ˆí¬  \n",
    "- `MUSR`: ìì—°ì–´ë¡œ ë¬˜ì‚¬ëœ ì¶”ë¡  ë¬¸ì œë¥¼ í‘¸ëŠ” ë²¤ì¹˜ë§ˆí¬  \n",
    "- `MMLU-Pro`: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì–¸ì–´ ì´í•´ì™€ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7759ac6c",
   "metadata": {},
   "source": [
    "### 3. EXAONEì˜ íŠ¹ì§•  \n",
    ": `ê·¸ë£¹ ì¿¼ë¦¬ ì–´í…ì…˜`ì„ ì‚¬ìš© == ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ë³€í˜•  \n",
    ": `ë©€í‹° ì¿¼ë¦¬ ì–´í…ì…˜`ì€ ëª¨ë“  í—¤ë“œì—ì„œ í‚¤ì™€ ê°’ì„ ê³µìœ í•˜ì§€ ì•Šê³ , ëª‡ ê°œì˜ í—¤ë“œì”© ë‚˜ëˆ ì„œ ê³µìœ í•˜ëŠ” ë°©ì‹ì´ ê·¸ë£¹ ì¿¼ë¦¬  \n",
    ": ì¼ë°˜ì ìœ¼ë¡œ ì‹¤ë£¨ í•¨ìˆ˜ë¥¼ ì ìš©í•  ë•Œ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì˜ ì²« ë²ˆì§¸ ë°€ì§‘ì¸µì„ ë‘ ê°œë¡œ ë‚˜ëˆ„ì–´ í•˜ë‚˜ëŠ” `ì‹¤ë£¨ í•¨ìˆ˜`ë¥¼ ì ìš©í•˜ê³ , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” í™œì„±í™” í•¨ìˆ˜ë¥¼ ì ìš©X  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c94ac6c",
   "metadata": {},
   "source": [
    "* `RMS ì •ê·œí™”`: ì •ê·œí™”ë¥¼ í•  ë•Œ í‰ê· ì„ êµ¬í•˜ì§€ ì•ŠëŠ” ë°©ë²•  \n",
    "* `ë¡œí„°ë¦¬ ìœ„ì¹˜ ì„ë² ë”©`: ì¿¼ë¦¬ì™€ í‚¤ ë²¡í„°ë¥¼ ì„œë¡œ ë‹¤ë¥¸ ê°ë„ë¡œ íšŒì „"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86418453",
   "metadata": {},
   "source": [
    "#### 3.1 EXAONE-3.5ë¡œ ìƒí’ˆ ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µ ìƒì„±í•˜ê¸°  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "779bd28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd72185bb69b4176a80fade47e8827a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69eca8ea3b79493d81aa1c23a7b4ca54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11cfc662cd6f4b7cb3089ee0b2589100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcb45f33f6b4f82bd8fc57a8fae4526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a658b29abec4f72a98ee1830cd44c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/563 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "exaone_tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9c0907d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 13:26:33.937072: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-10 13:26:34.144999: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-10 13:26:36.525538: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7b8a37f2e840e4a3a565db72b58cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f9ad33477240e0b5a5ec86eeb2d28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_exaone.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct:\n",
      "- configuration_exaone.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a113b9b7d64d0d8c09a4f891642ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_exaone.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct:\n",
      "- modeling_exaone.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c698cd7eb8bf429f95be40734ba8490a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d75606a4a64421988750c7fbb628e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6698b87a17b24340a92553b19558a667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabcedd6d86746a7bcf24033f48f2338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.65G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f06c1c4533042a2bf24ac64ff16a594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256507ffde5045ea87853684a40a82ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# pipeline() í•¨ìˆ˜ì˜ tokenizer ë§¤ê°œë³€ìˆ˜ë¡œ exaone_tokenizerë¥¼ ì „ë‹¬\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\",\n",
    "                model=\"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\",\n",
    "                tokenizer=exaone_tokenizer,\n",
    "                device=0, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f66942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'role'ì„ 'system'ìœ¼ë¡œ ì§€ì •í•˜ê³  EXAONE ëª¨ë¸ì´ ì–´ë–¤ ì—­í• ì„ ë§¡ê²Œ ë˜ëŠ”ì§€ í™•ì¸\n",
    "messages = [\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"ë„ˆëŠ” ì‡¼í•‘ëª° í™ˆí˜ì´ì§€ì— ì˜¬ë¼ì˜¨ ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ëŠ” Q&A ì±—ë´‡ì´ì•¼.\\\n",
    "                 í™•ì •ì ì¸ ë‹µë³€ì„ í•˜ì§€ ë§ê³  ì œí’ˆ ë‹´ë‹¹ìê°€ ì •í™•í•œ ë‹µë³€ì„ í•˜ê¸° ìœ„í•´\\\n",
    "                 ì‹œê°„ì´ í•„ìš”í•˜ë‹¤ëŠ” ê°„ë‹¨í•˜ê³  ì¹œì ˆí•œ ë‹µë³€ì„ ìƒì„±í•´ì¤˜.\"},\n",
    "    {\"role\":\"user\",\"content\": \"ì´ ë‹¤ì´ì–´ë¦¬ì— ë‚´ë…„ë„ ê³µíœ´ì¼ì´ í‘œì‹œë˜ì–´ ìˆë‚˜ìš”?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e77317bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'system',\n",
       "    'content': 'ë„ˆëŠ” ì‡¼í•‘ëª° í™ˆí˜ì´ì§€ì— ì˜¬ë¼ì˜¨ ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ëŠ” Q&A ì±—ë´‡ì´ì•¼.                 í™•ì •ì ì¸ ë‹µë³€ì„ í•˜ì§€ ë§ê³  ì œí’ˆ ë‹´ë‹¹ìê°€ ì •í™•í•œ ë‹µë³€ì„ í•˜ê¸° ìœ„í•´                 ì‹œê°„ì´ í•„ìš”í•˜ë‹¤ëŠ” ê°„ë‹¨í•˜ê³  ì¹œì ˆí•œ ë‹µë³€ì„ ìƒì„±í•´ì¤˜.'},\n",
       "   {'role': 'user', 'content': 'ì´ ë‹¤ì´ì–´ë¦¬ì— ë‚´ë…„ë„ ê³µíœ´ì¼ì´ í‘œì‹œë˜ì–´ ìˆë‚˜ìš”?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'ì•ˆë…•í•˜ì„¸ìš”! ë‹¤ì´ì–´ë¦¬ì— ë‚´ë…„ë„ ê³µíœ´ì¼ì´ ë¯¸ë¦¬ í‘œì‹œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ ë“œë¦¬ê³  ì‹¶ì§€ë§Œ, ì œê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ì œí’ˆ ì •ë³´ë¥¼ ì§ì ‘ í™•ì¸í•  ìˆ˜ëŠ” ì—†ì–´ì„œ ì •í™•íˆ ë§ì”€ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì œí’ˆ ë‹´ë‹¹ìì—ê²Œ ë¬¸ì˜í•˜ì‹œê±°ë‚˜, ê³ ê° ì„œë¹„ìŠ¤ ì„¼í„°ì— ì—°ë½í•˜ì‹œë©´ ê°€ì¥ ì •í™•í•œ ì •ë³´ë¥¼ ì–»ìœ¼ì‹¤ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”. ê·¸ë¶„ë“¤ê»˜ì„œ ìì„¸íˆ ì•ˆë‚´í•´ ì£¼ì‹¤ ê±°ì˜ˆìš”! ê°ì‚¬í•©ë‹ˆë‹¤.'}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(messages, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dd047a",
   "metadata": {},
   "source": [
    "í”„ë¡¬í”„íŠ¸ë¡œ ì…ë ¥í•œ ë‚´ìš©ì„ ë‹¤ì‹œ í™•ì¸í•  í•„ìš”ëŠ” ì—†ìœ¼ë‹ˆ ëª¨ë¸ì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ë ¤ë©´ return_full_text ë§¤ê°œë³€ìˆ˜ë¥¼ Fasleë¡œ ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62a20b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'ë„¤, ì €í¬ ì‹œìŠ¤í…œìœ¼ë¡œëŠ” ë‹¤ì´ì–´ë¦¬ì— ì •í™•í•˜ê²Œ í‘œì‹œëœ ë‚´ë…„ë„ ê³µíœ´ì¼ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì •í™•í•œ ê³µíœ´ì¼ ì •ë³´ë¥¼ í™•ì¸í•˜ë ¤ë©´ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ìì—ê²Œ ë¬¸ì˜í•˜ì‹œê±°ë‚˜, ì§ì ‘ ì €í¬ ì‡¼í•‘ëª°ì— ë°©ë¬¸í•´ ì£¼ì‹œë©´ ë” ë¹ ë¥´ê²Œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(messages, max_new_tokens=500, return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d00b40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì£„ì†¡í•©ë‹ˆë‹¤ë§Œ, ì €ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì œí’ˆ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸ ë°›ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì— ì •í™•í•œ ë‹µë³€ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤. ë‚´ë…„ë„ ê³µíœ´ì¼ ì •ë³´ëŠ” ì œí’ˆ ì„¤ëª…ì„œë‚˜ ê³ ê°ì„¼í„°ë¡œ ë¬¸ì˜í•˜ì‹œë©´ ê°€ì¥ ì •í™•í•œ ë‹µë³€ì„ ì–»ìœ¼ì‹¤ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”. ë„ì›€ì´ ë˜ì…¨ê¸¸ ë°”ëë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "output = pipe(messages, max_new_tokens=200, return_full_text=False, do_sample=True)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ba619",
   "metadata": {},
   "source": [
    "do_sample ë§¤ê°œë³€ìˆ˜ë¥¼ Trueë¡œ ì§€ì •í•˜ë‹ˆ ë‹µë³€ì´ ì¡°ê¸ˆ ë” ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7814d321",
   "metadata": {},
   "source": [
    "### 4. í† í° ë””ì½”ë”© ì „ëµ  \n",
    ": ë³´í†µ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ê¸° ì „ì˜ ê°’ì„ `ë¡œì§“`ì´ë¼ ë¶€ë¦„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20b1d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "logits = np.array([1,2,3,4,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "669f132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.01122149e-43 2.74878501e-43 7.47197234e-43 2.03109266e-42\n",
      " 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "probas = softmax(logits)\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eaa2deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0, 100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.multinomial(100, probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f7e22",
   "metadata": {},
   "source": [
    "ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë‹ˆ ë§ˆì§€ë§‰ ì›ì†Œë§Œ ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b91230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 10, 20, 16, 37])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = softmax(logits/100)\n",
    "np.random.multinomial(100,probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5af5852",
   "metadata": {},
   "source": [
    "1ë³´ë‹¤ í° ê°’ìœ¼ë¡œ ë‚˜ëˆ„ë©´ í™•ë¥  ë¶„í¬ê°€ ì¡°ê¸ˆ ë” ë¶€ë“œëŸ¬ì›Œì ¸ ë‹¤ë¥¸ ì›ì†Œê°€ ì„ íƒë  ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae38aff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë””ì–´ ìƒë‹´ì›ì…ë‹ˆë‹¤ ğŸ™‚ í˜„ì¬ ë‹¤ì´ì–´ë¦¬ í•­ëª© ì„¤ëª… ì¤‘ ì§ˆë¬¸ ì²˜ë¦¬í•˜ê³  ë„˜ì–´ê°€ê¸° ìœ„í•´ì„œ í•œì • ê³µê°„ì´ë‹ˆ ê°œë³„ ë‚´ìš© ë¶„ì„ì—time ì‹œê°„ì´ê°€ Requiredë˜ê²Œ í•˜ë‹¤ê°€ exact response For your information detailing regarding Christmas festive days are likely printed Inside on calendar days marked specifically For December ahead, But For comprehensive Lists such Preferences & Nationalholiding holidays that precisely Tailorenting to Country Spectific details Might Requires Review Behind the Screws of Current Holiday Design Our aim Goes Toward customer Guidance ensuring Every Inquiry Arriver Well Prepared with Clear Steps towards Confirmation Let My Developers Catch Back To Provide Direct Assistance ASAP cheers & Have Better Day ğŸ‘ˆğŸ·ã€‚ **(ì„¤ëª… ë‚´ìš© ê²€í†  ì¤‘ì´ë¡œ ì¶”ê°€ ì¼ì • í•„ìš”ì—, ëŒ€í•œë¯¼êµ­ì˜ ì—° ë‹¬ë ¥holidas ë‚ ì§œ ì—¬ë¶€ ìš°ì„  ì‚´í´ë³´ê² ìœ¼ë‚˜ ìì„¸ì•ˆë‚´ ë¶€íƒë“œë¦½ë‹ˆë‹¤ ì§ì ‘í™•ì¸ ë° ë” ì •êµí•œ ì •ë³´ìš”ì² í•´ë“œãƒªë§ˆí‚µë‹ˆë‹¤ ** ê°ì‚¬í• í…Œìš” ê·¸ë¦¬ê³  ë°”ë¡œ íšŒì‹ í• ê²ƒì„ ë¶€íƒë“œë ¤ìš” â˜º\" í™•ì¸ë˜ìš” í¬ë¦¬ìŠ¤ë§ˆìŠ¤ íœ´ì¼ í¬í•¨ëœ ê³µíœ´ì¼ì„ ìº˜ë¦°ë”ì™€ ë™ì¼ ì¥ì†Œì— ë³´ì—¬ì§€ë‹ˆ ê´€ì‹¬ ì§€ì—­ íŠ¹ë³„íˆ ë³€ê²½ ì‚¬í•­ ìœ ë¬´ ì•Œì•„ë³´ì‹œ\n"
     ]
    }
   ],
   "source": [
    "output = pipe(messages, max_new_tokens=200, return_full_text=False,\n",
    "              do_sample=True, temperature=10.0)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15542c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ë‹¤ì´ì–´ë¦¬ì— ë‚´ë…„ì˜ ê³µíœ´ì¼ì´ ë¯¸ë¦¬ í‘œì‹œë˜ì–´ ìˆëŠ”ì§€ì— ëŒ€í•´ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ì„œëŠ” ì œí’ˆ ë‹´ë‹¹ìì—ê²Œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬ë¡œì„  ì§ì ‘ í™•ì¸ì´ ì–´ë ¤ìš°ë‹ˆ, ì €í¬ê°€ ì•ˆë‚´ë“œë¦´ ìˆ˜ ìˆëŠ” ë°©ë²•ìœ¼ë¡œëŠ” ê³ ê°ì„¼í„°ì— ì—°ë½í•˜ì‹œê±°ë‚˜, ì œí’ˆ í˜ì´ì§€ ë‚´ì˜ ë¬¸ì˜ ê²Œì‹œíŒì„ í†µí•´ ì§ˆë¬¸í•´ ë³´ì‹œëŠ” ê²ƒì´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë‹´ë‹¹ìë¶„ê»˜ì„œ ë¹ ë¥´ê²Œ ë‹µë³€í•´ ì£¼ì‹¤ ê±°ì˜ˆìš”! ê°ì‚¬í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "output = pipe(messages, max_new_tokens=200, return_full_text=False,\n",
    "              do_sample=True, temperature=0.001)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f3bdf",
   "metadata": {},
   "source": [
    "#### 4.1 top-k ìƒ˜í”Œë§  \n",
    ": ëª¨ë¸ì´ ì¶œë ¥í•œ ë¡œì§“ì„ ê¸°ì¤€ìœ¼ë¡œ ìµœìƒìœ„ kê°œì˜ í† í°ì„ ì„ íƒí•˜ëŠ” ë°©ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c72dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤, ë‹¤ì´ì–´ë¦¬ì— ë‚´ë…„ì˜ ê³µíœ´ì¼ë“¤ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ì— ëŒ€í•´ ì •í™•íˆ ì•Œë ¤ë“œë¦¬ê¸° ìœ„í•´ì„œëŠ” ì œí’ˆ ë‹´ë‹¹ìì—ê²Œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. ë‹´ë‹¹ìë‹˜ê»˜ì„œ í™•ì¸í•´ ì£¼ì‹œë©´ ê°€ì¥ ì •í™•í•œ ì •ë³´ë¥¼ ë“œë¦´ ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. í˜¹ì‹œ ê°€ëŠ¥í•˜ì‹œë‹¤ë©´ ì§ì ‘ ì—°ë½ì„ ì·¨í•´ë³´ì‹œê±°ë‚˜, ê³ ê°ì„¼í„°ë¥¼ í†µí•´ ë¬¸ì˜í•´ ë³´ì‹œëŠ” ê²ƒë„ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”! ê¸°ë‹¤ë¦¬ë©´ì„œ ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ê°ì‚¬í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "output = pipe(messages, max_new_tokens=200, return_full_text=False,\n",
    "              do_sample=True, top_k=10)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f592f76",
   "metadata": {},
   "source": [
    "* transformers íŒ¨í‚¤ì§€ëŠ” ì˜¨ë„ íŒŒë¼ë¯¸í„°ë¥¼ top-k ìƒ˜í”Œë¦¬ì´ë‚˜ ì´ì–´ì„œ ì„¤ëª…í•  top-p ìƒ˜í•„ë§ ë³´ë‹¤ ë¨¼ì € ì ìš©!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b27a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤ ~, ì§ˆë¬¸í•˜ì…”ì„œ ê³ ë§ˆì›Œìš”. ì œí’ˆ ë‹´ë‹¹ì´ ì •í™•í•œ ìƒíƒœë‚˜ ì„¸ë¶€ í•­ëª©ì— ëŒ€í•´ì„œ ìì„¸íˆ ì•Œì•„ë³´ë ¤ê³  ë…¸ë ¥ì„ ê¸°ìš¸ì¼ í•„ìš”ê°€ìš”... í˜„ì¬ ë‹¤ì´ì–´ë¦¬ì—ë‚´ë…„ ë‹¬ë ¥ ì •ë³´ëŠ” ëª¨ë‘ ì¸ì‡„ê°€ ëœ ê³³ì„ í™•ì¸í•  í…Œê³ , í˜¹ì‹œ ë” ìì„¸í•œ ë¶€ë¶„ì€ ì œí’ˆ ë‹´ë‹¹ìë‚˜ê³ ê°ì„œë¹„ìŠ¤ ì„¼í„°ë¡œë¬¸ì˜í•˜ì‹œì–´ ì •í™•í•˜ì‹œê¸¸ ê¸°ì›í•´ìš”. ê³§ ì¢‹ ì†Œì‹ ì•Œë ¤ë“œë¦¬ê²Ÿì§€ë§Œ ì ê¹ ê¸°ë‹¤ë ¤ì£¼ì‹œê²Ÿë‚˜ìš”??\n"
     ]
    }
   ],
   "source": [
    "output = pipe(messages, max_new_tokens=200, return_full_text=False,\n",
    "              do_sample=True, top_k=10, temperature=10.0)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cbe61e",
   "metadata": {},
   "source": [
    "#### 4.2 top-p ìƒ˜í”Œë§  \n",
    ": top-k ìƒ˜í”Œë§ê³¼ ë‹¤ë¥´ê²Œ ìµœìƒìœ„ í† í°ì˜ ê°œìˆ˜ë¥¼ ê³ ì •í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ í™•ë¥  ìˆœìœ¼ë¡œ í† í°ì„ ë‚˜ì—´í•œ í›„ ì‚¬ì „ì— ì§€ì •í•œ í™•ë¥ ë§Œí¼ë§Œ ìµœìƒìœ„ í† í°ì„ ì„ íƒí•˜ëŠ” ë°©ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e9fb985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤, ë§ìŠµë‹ˆë‹¤! ë‹¤ì´ì–´ë¦¬ì— ë‚´ë…„ì˜ ê³µíœ´ì¼ë“¤ì´ ì˜ í‘œì‹œë˜ì–´ ìˆì„ ê±°ì˜ˆìš”. í•˜ì§€ë§Œ ì •í™•í•œ ë‚´ìš©ì„ í™•ì¸í•˜ë ¤ë©´ ì €í¬ê°€ ì§ì ‘ í™•ì¸í•´ë´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ë¡œì„  í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­ì´ë‹ˆ, ì¡°ê¸ˆ ë” ì‹œê°„ì´ ê±¸ë¦¬ê² ì§€ë§Œ ê³§ ë‹´ë‹¹ìê»˜ì„œ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ê±°ì˜ˆìš”. ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ì‹œë‹¤ë©´ ì–¸ì œë“ ì§€ ì•Œë ¤ì£¼ì„¸ìš”! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "output = pipe(messages, max_new_tokens=200, return_full_text=False,\n",
    "              do_sample=True, top_p=0.9)  # LLMì´ ë‹¤ìŒ í† í°ì„ ì„ íƒí•  ë•Œ ëª¨ë‘ í•©ì³ì„œ 90% í™•ë¥  ì•ˆì— ë“œëŠ” í† í°ë§Œì„ ì‚¬ìš©\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0de0525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì œí’ˆ ì„¤ëª…ì„œë‚˜ ë‹¤ì´ì–´ë¦¬ ì•ˆì— ì—°ë§ ê³„íšì´ë‚˜ ì—…ë°ì´íŠ¸ ê³„íš í‘œì‹œì¼ë ¨ì´ ìì„¸í•˜ê¸´ í•˜ì§€ë§Œ, ì§€ê¸ˆ ì—°ë½ë“œì…”ì„œ ë‚´ë…„ Holidays specifically í‘œê¸°ê°€ ì •í™•íˆ ì–´ëŠ í˜ì´ì§€ í˜¹ì€ ìœ„ì¹˜ì¸ì§€ ì •í™•íˆ ë§í•˜ê¸° ì–´ë ¤ì›Œìš”. ìì„¸í•œ ë‚´ìš©ì€ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì—°ë½ ë¶€íƒë“œë¦½ë‹ˆë‹¤! ê³§ í™•ì¸ì„ ì™„ë£Œí•  ë‹´ë‹¹ìë¶„ê»˜ ë‹¤ì‹œ ì—°ë½ë“œë¦´ê²Œìš” ğŸ˜Š ê³„ì† ë„ì™€ë“œë¦´ê²Œìš”, í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "output = pipe(messages, max_new_tokens=200, return_full_text=False,\n",
    "              do_sample=True, temperature=2.0, top_k=100, top_p=0.9)  # LLMì´ ë‹¤ìŒ í† í°ì„ ì„ íƒí•  ë•Œ ëª¨ë‘ í•©ì³ì„œ 90% í™•ë¥  ì•ˆì— ë“œëŠ” í† í°ë§Œì„ ì‚¬ìš©\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e5759",
   "metadata": {},
   "source": [
    "### 5. ì˜¤í”ˆAI APIë¡œ ìƒí’ˆ ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µ ìƒì„±í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34c2ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4c571f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "590aa970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ë¬¸ì˜ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. í•´ë‹¹ ë‹¤ì´ì–´ë¦¬ì— ë‚´ë…„ë„ ê³µíœ´ì¼ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•  ê²ƒ ê°™ì•„ìš”. ì œí’ˆ ë‹´ë‹¹ìê°€ í™•ì¸ í›„ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆë„ë¡ ì¡°ê¸ˆë§Œ ê¸°ë‹¤ë ¤ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3258be94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ë¬¸ì˜í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. í•´ë‹¹ ë‹¤ì´ì–´ë¦¬ì— ë‚´ë…„ë„ ê³µíœ´ì¼ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ì œí’ˆ ë‹´ë‹¹ìì—ê²Œ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. ì¡°ê¸ˆë§Œ ê¸°ë‹¤ë ¤ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    top_p=0.9\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88242da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ë¬¸ì˜ ì£¼ì…”ì„œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ë‚´ë…„ë„ ê³µíœ´ì¼ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ ë³´ê¸° ìœ„í•´ ì´ ë¬¸ì˜ ë‚´ìš©ì„ í•´ë‹¹ ì œí’ˆ ë‹´ë‹¹ìì—ê²Œ ì „ë‹¬í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ì¡°ê¸ˆë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”. ê³ ê°ë‹˜ë“¤ì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µë³€ ë“œë¦´ ìˆ˜ ìˆë„ë¡ ìµœì„ ì„ ë‹¤í• ê²Œìš”!\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature = 1.8\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81b94a",
   "metadata": {},
   "source": [
    "- ì˜¤í”ˆAIì˜ temperature ë§¤ê°œë³€ìˆ˜ëŠ” 0~2 ì‚¬ì´ì˜ ê°’ì„ ì§€ì •í•´ì•¼ í•˜ë©° ê¸°ë³¸ê°’ì€ 1ì´ë‹¤.  \n",
    "- temperature ê°’ì„ ì¦ê°€ì‹œí‚¤ë‹ˆ ë¶ˆì•ˆì •í•œ ë‹µì´ ì¶œë ¥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
